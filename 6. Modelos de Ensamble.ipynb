{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e14a87b-11b4-4c00-8158-738326d98474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. **Modelos de Ensamble**\n",
    "   - **Utilidad:** Este grupo de métodos se utiliza para combinar múltiples modelos base para mejorar el rendimiento y la robustez del modelo final.\n",
    "   - **Funciones comunes:**\n",
    "     - **BaggingClassifier/Regressor:** Ensamble de modelos usando bagging.\n",
    "     - **AdaBoostClassifier/Regressor:** Ensamble de modelos usando boosting adaptativo.\n",
    "     - **VotingClassifier/Regressor:** Ensamble de múltiples modelos mediante votación o promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2a9554-526a-463d-8d46-500648cbc75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cargar y preparar los datos de regresión\n",
    "Cargamos el dataset California housing y dividimos los datos en conjuntos de entrenamiento y prueba para regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08ed17c1-d973-428b-a16c-d758e9e6c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "housing = fetch_california_housing()\n",
    "X_reg = housing.data\n",
    "y_reg = housing.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3cb7f6-ea07-43a8-9846-4e67bdf3bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cargar y preparar los datos de clasificación\n",
    "Cargamos el dataset Wine y dividimos los datos en conjuntos de entrenamiento y prueba para clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfaf0611-447b-432a-9e91-30e98e7b40b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = load_wine()\n",
    "X_clf = data.data\n",
    "y_clf = data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X_clf, y_clf, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aca15a-d3db-4785-95ef-ed195f4ce4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BaggingRegressor\n",
    "Entrenamos y evaluamos un regresor Bagging con un árbol de decisión como base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cbe3ef0-874d-4d06-8648-517abf3c1e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor MSE: 0.26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the BaggingRegressor with DecisionTreeRegressor as base estimator\n",
    "model = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Bagging Regressor MSE: {mse:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2291b7c-7a96-456f-b33c-fc4e3ea9ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BaggingClassifier\n",
    "Entrenamos y evaluamos un clasificador Bagging con un árbol de decisión como base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6886ae87-9a5e-4e5b-8627-2955f092e622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the BaggingClassifier with DecisionTreeClassifier as base estimator\n",
    "model_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_clf.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred_clf = model_clf.predict(X_test_clf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_clf, y_pred_clf)\n",
    "print(f'Bagging Classifier Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cfb6bc-54cd-4e8a-995d-20bb1ea0fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AdaBoostRegressor\n",
    "Entrenamos y evaluamos un regresor AdaBoost con un árbol de decisión como base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79db60b0-acfd-4bed-9cc7-cfbc036bb353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Regressor MSE: 0.80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Initialize the AdaBoostRegressor with DecisionTreeRegressor as base estimator\n",
    "model = AdaBoostRegressor(estimator=DecisionTreeRegressor(max_depth=4), n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'AdaBoost Regressor MSE: {mse:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00cf4f7-eda7-4256-b65a-dd6db67ee05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AdaBoostClassifier\n",
    "Entrenamos y evaluamos un clasificador AdaBoost con un árbol de decisión como base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1a332a1-17fe-4d54-bd1b-37ddb501e54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the AdaBoostClassifier with DecisionTreeClassifier as base estimator and SAMME algorithm\n",
    "model_clf = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1), n_estimators=50, algorithm='SAMME', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_clf.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred_clf = model_clf.predict(X_test_clf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_clf, y_pred_clf)\n",
    "print(f'AdaBoost Classifier Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb1f40-3a35-40de-80cc-67132ea836de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VotingRegressor\n",
    "Entrenamos y evaluamos un regresor de votación con tres regresores base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf7ed25e-1012-4875-8dca-d228ce24124f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Regressor MSE: 0.46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the base regressors\n",
    "reg1 = LinearRegression()\n",
    "reg2 = DecisionTreeRegressor()\n",
    "reg3 = KNeighborsRegressor()\n",
    "\n",
    "# Initialize the VotingRegressor\n",
    "model = VotingRegressor(estimators=[\n",
    "    ('lr', reg1), \n",
    "    ('dt', reg2), \n",
    "    ('knn', reg3)])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Voting Regressor MSE: {mse:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a177ca3-4a41-4985-830a-869b871cf2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VotingClassifier\n",
    "Entrenamos y evaluamos un clasificador de votación con tres clasificadores base.\n",
    "- Utilizamos StandardScaler para escalar los datos en los clasificadores LogisticRegression y SVC.\n",
    "- Aumentamos max_iter en LogisticRegression para asegurar la convergencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd35dbe0-b9d9-4f6f-ac63-30a64df7decd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Initialize the base classifiers with a pipeline for scaling and increased max_iter for LogisticRegression\n",
    "clf1 = make_pipeline(StandardScaler(), LogisticRegression(max_iter=500))\n",
    "clf2 = KNeighborsClassifier(n_neighbors=3)\n",
    "clf3 = make_pipeline(StandardScaler(), SVC(kernel='linear', probability=True))\n",
    "\n",
    "# Initialize the VotingClassifier\n",
    "model_clf = VotingClassifier(estimators=[\n",
    "    ('lr', clf1), \n",
    "    ('knn', clf2), \n",
    "    ('svc', clf3)], voting='soft')\n",
    "\n",
    "# Train the model\n",
    "model_clf.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred_clf = model_clf.predict(X_test_clf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_clf, y_pred_clf)\n",
    "print(f'Voting Classifier Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d39fd3-59a7-4ec5-84a5-615fd5796e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
